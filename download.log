nohup: no se tendr√° en cuenta la entrada
/mnt/DATA/repos/Personal/jarvisIAV2/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/mnt/DATA/repos/Personal/jarvisIAV2/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:979: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.
For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.
  warnings.warn(
[95m[1m======================================================================[0m
[95m[1müöÄ Jarvis IA V2 - Descarga de Modelos[0m
[95m[1m======================================================================[0m
[94m‚ÑπÔ∏è  Espacio libre en disco: 178 GB[0m
[92m‚úÖ Espacio en disco suficiente: 178GB[0m
[95m[1m======================================================================[0m
[95m[1müì¶ Categor√≠a: LLM_FLAGSHIP[0m
[95m[1m======================================================================[0m

[1/1] Llama-3.3-70B-Instruct-AWQ
  GPU: GPU0 (RTX 5070 Ti) | VRAM: 14GB
  üèÜ FLAGSHIP √öNICO - Modelo m√°s potente, carga solo este
[94m‚ÑπÔ∏è  Descargando Llama-3.3-70B-Instruct-AWQ...[0m
[94m‚ÑπÔ∏è    Repositorio: casperhansen/llama-3.3-70b-instruct-awq[0m
[94m‚ÑπÔ∏è    Tama√±o estimado: ~40GB[0m
[94m‚ÑπÔ∏è    Destino: models/llm/llama-3.3-70b-awq[0m
Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]