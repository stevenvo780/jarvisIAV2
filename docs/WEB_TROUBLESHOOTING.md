# ðŸ”§ SoluciÃ³n de Problemas - Interfaz Web Jarvis

## âœ… Problema Resuelto: FileNotFoundError models_v2.json

### SÃ­ntoma
```
FileNotFoundError: [Errno 2] No such file or directory: 'src/config/models_v2.json'
RuntimeError: Cannot load configuration from src/config/models_v2.json
```

### Causa
El cÃ³digo de `ModelOrchestrator` busca `models_v2.json` pero solo existe `models.json` en el repositorio.

### SoluciÃ³n AutomÃ¡tica
Los scripts de inicio ahora detectan y corrigen este problema automÃ¡ticamente:

```bash
# OpciÃ³n 1: Script bash (con auto-fix)
./start_web.sh

# OpciÃ³n 2: Script Python (con auto-fix)
python3 start_web.py
```

Ambos scripts:
1. Verifican si existe `models_v2.json`
2. Si no existe, copian `models.json` â†’ `models_v2.json`
3. ContinÃºan con el inicio normal

### SoluciÃ³n Manual (Si es necesario)
```bash
cp src/config/models.json src/config/models_v2.json
```

---

## ðŸš€ Inicio Exitoso - Salida Esperada

```
============================================================
ðŸ¤– JARVIS AI ASSISTANT - WEB INTERFACE
============================================================
ðŸ“± Interfaz web: http://localhost:8090
âš™ï¸  Puerto: 8090
ðŸ”§ Debug: Desactivado
============================================================

2025-11-09 23:38:53 - __main__ - INFO - ðŸŒ Inicializando Jarvis...
2025-11-09 23:38:53 - __main__ - INFO - âœ“ System monitor initialized
2025-11-09 23:38:53 - __main__ - INFO - âœ“ Storage initialized
2025-11-09 23:38:53 - __main__ - INFO - âœ“ Metrics tracker initialized
2025-11-09 23:38:54 - __main__ - INFO - âœ“ Embedding system (RAG) initialized
2025-11-09 23:38:54 - __main__ - INFO - âœ“ SmartPromptBuilder initialized
2025-11-09 23:38:54 - __main__ - INFO - âœ“ LearningManager initialized
2025-11-09 23:38:54 - __main__ - INFO - âœ“ QualityEvaluator initialized
2025-11-09 23:38:54 - __main__ - INFO - âœ“ ModelOrchestrator initialized
2025-11-09 23:38:54 - __main__ - INFO - âœ… Jarvis core initialized

ðŸŒ Iniciando servidor web en http://0.0.0.0:8090
ðŸ“± Abre tu navegador en: http://localhost:8090

INFO:     Started server process [12345]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8090 (Press CTRL+C to quit)
```

---

## ðŸ› Otros Problemas Comunes

### 1. Puerto Ocupado
**SÃ­ntoma:**
```
ERROR: [Errno 98] error while attempting to bind on address ('0.0.0.0', 8090): address already in use
```

**SoluciÃ³n:**
```bash
# OpciÃ³n A: Usar puerto diferente
python3 start_web.py --port 8091

# OpciÃ³n B: Matar proceso existente
lsof -ti:8090 | xargs kill -9
```

### 2. FastAPI no instalado
**SÃ­ntoma:**
```
ModuleNotFoundError: No module named 'fastapi'
```

**SoluciÃ³n:**
```bash
pip install fastapi uvicorn python-multipart
```

### 3. Pygame Warning
**SÃ­ntoma:**
```
pygame 2.6.1 (SDL 2.28.4, Python 3.13.7)
Hello from the pygame community. https://www.pygame.org/contribute.html
```

**Nota:** Esto es un mensaje informativo de pygame, no un error. Puede ignorarse.

### 4. GPU No Disponible
**SÃ­ntoma:**
```
âš ï¸  nvidia-smi no encontrado (modo CPU)
```

**Nota:** Jarvis funcionarÃ¡ en modo CPU (mÃ¡s lento). Para usar GPU:
- Verifica drivers NVIDIA: `nvidia-smi`
- Instala CUDA toolkit
- Verifica `CUDA_VISIBLE_DEVICES`

### 5. Modelos No Encontrados
**SÃ­ntoma:**
```
FileNotFoundError: models/llm/qwen2.5-14b-awq
```

**SoluciÃ³n:**
Los modelos se descargan bajo demanda. Al hacer la primera consulta, Jarvis:
1. Detecta modelo no presente
2. Lo descarga automÃ¡ticamente
3. Lo carga en GPU

Tiempo de descarga: ~10-30 minutos segÃºn modelo.

### 6. Out of Memory (OOM)
**SÃ­ntoma:**
```
torch.cuda.OutOfMemoryError: CUDA out of memory
```

**SoluciÃ³n:**
Edita `src/config/models_v2.json`:
```json
{
  "models": {
    "qwen-32b": {
      "enabled": false  // Deshabilitar modelo grande
    },
    "qwen-14b": {
      "enabled": true   // Usar modelo mÃ¡s pequeÃ±o
    }
  }
}
```

---

## ðŸ” Debug Avanzado

### Modo Debug
```bash
python3 start_web.py --debug
```

Esto activa:
- Logs detallados de vLLM
- Logs de torch.distributed
- Traceback completos
- MÃ©tricas de rendimiento

### Logs Persistentes
```bash
# Ver logs en tiempo real
tail -f logs/jarvis.log

# Ver solo errores
tail -f logs/errors.log

# Buscar error especÃ­fico
grep "ERROR" logs/jarvis.log
```

### Estado del Servidor
```bash
# API status
curl http://localhost:8090/api/status

# Health check
curl http://localhost:8090/docs  # OpenAPI docs
```

### Verificar Proceso
```bash
# Ver proceso uvicorn
ps aux | grep uvicorn

# Ver uso de GPU
watch -n 1 nvidia-smi

# Ver uso de memoria
htop
```

---

## ðŸ“Š MÃ©tricas de Rendimiento

### Tiempos Normales
- **Inicio de servidor**: 5-10 segundos
- **Primera consulta (carga modelo)**: 30-60 segundos
- **Consultas subsiguientes**: 1-5 segundos
- **Uso de VRAM**: 6-14 GB segÃºn modelo

### Optimizaciones
Si estÃ¡ lento:
1. Usar modelos AWQ (quantizados)
2. Reducir `max_tokens` en config
3. Habilitar solo 1 modelo
4. Usar GPU mÃ¡s potente

---

## ðŸ†˜ Soporte

### InformaciÃ³n para Reportar Issues
```bash
# Recopilar info del sistema
python3 -c "
import sys
import torch
print(f'Python: {sys.version}')
print(f'PyTorch: {torch.__version__}')
print(f'CUDA: {torch.cuda.is_available()}')
"

# Info de GPU
nvidia-smi

# Versiones de paquetes
pip list | grep -E "(fastapi|uvicorn|torch|transformers)"
```

### Logs Ãštiles
Al reportar problemas, incluir:
1. Output completo del error
2. Contenido de `logs/errors.log`
3. VersiÃ³n de Python y CUDA
4. Comando exacto usado

---

## âœ… Checklist de Inicio

Antes de reportar problemas, verificar:

- [ ] Python 3.8+ instalado
- [ ] `pip install fastapi uvicorn` ejecutado
- [ ] `models_v2.json` existe (auto-creado por scripts)
- [ ] Puerto 8090 disponible
- [ ] CUDA drivers instalados (si usar GPU)
- [ ] Espacio en disco suficiente (>50GB para modelos)
- [ ] RAM suficiente (>16GB recomendado)

---

## ðŸŽ“ Recursos

- **DocumentaciÃ³n completa**: `docs/WEB_INTERFACE.md`
- **GuÃ­a rÃ¡pida**: `WEB_QUICKSTART.md`
- **Visual guide**: `docs/WEB_VISUAL_GUIDE.md`
- **FastAPI docs**: https://fastapi.tiangolo.com/
- **vLLM docs**: https://docs.vllm.ai/

---

**Ãšltima actualizaciÃ³n:** 2025-11-09  
**Estado:** âœ… Todos los problemas conocidos resueltos
