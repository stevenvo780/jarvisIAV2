# Sistema de Logs Limpios para Jarvis

## ğŸ¯ Objetivo
Mantener la terminal limpia durante la ejecuciÃ³n de Jarvis, suprimiendo logs verbosos de librerÃ­as externas mientras se preserva la interfaz de usuario.

## ğŸ“‹ Problemas Identificados

### Antes de la Mejora
Cuando se ejecutaba Jarvis, aparecÃ­an logs tÃ©cnicos que contaminaban la interfaz:

```
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:00<00:00,  5.14it/s]
Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:00<00:00,  3.25it/s]
Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:00<00:00,  2.89it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [00:02<00:00,  5.15it/s]
Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  5.09it/s]
Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 529.85it/s]
```

**Fuentes de logs verbosos:**
- vLLM (safetensors, CUDA graphs, engine core)
- torch.distributed (Gloo)
- tqdm (barras de progreso)
- transformers, sentence_transformers
- httpx, asyncio

## ğŸ› ï¸ SoluciÃ³n Implementada

### 1. Nuevo MÃ³dulo: `src/utils/log_suppressor.py`

Implementa un sistema robusto de supresiÃ³n de logs con:

#### **Context Manager para Captura de Output**
```python
class SuppressedOutput:
    """Context manager para suprimir stdout/stderr selectivamente"""
    - Captura stdout/stderr durante operaciones ruidosas
    - Permite redirecciÃ³n a logs si se necesita debug
    - Siempre muestra errores crÃ­ticos
```

#### **ConfiguraciÃ³n de Entorno Silencioso**
```python
def configure_quiet_mode():
    """Configura variables de entorno y loggers para silenciar librerÃ­as"""
    - TF_CPP_MIN_LOG_LEVEL=3
    - TRANSFORMERS_VERBOSITY=error
    - VLLM_LOGGING_LEVEL=ERROR
    - GLOO_LOG_LEVEL=ERROR
    - Configura 15+ loggers problemÃ¡ticos
```

#### **SupresiÃ³n de tqdm**
```python
def suppress_tqdm():
    """Monkey-patch para deshabilitar barras de progreso"""
    - Intercepta tqdm.tqdm y tqdm.trange
    - Establece disable=True por defecto
```

#### **Context Manager para Carga de Modelos**
```python
@contextmanager
def model_loading_context(debug_mode: bool = False):
    """Context manager especÃ­fico para cargar modelos sin contaminar terminal"""
    - Si debug_mode=True, muestra todo
    - Si debug_mode=False, suprime output completo
    - AutomÃ¡tico basado en JARVIS_DEBUG
```

### 2. IntegraciÃ³n en `main.py`

```python
# ANTES de cualquier import pesado
from src.utils.log_suppressor import setup_clean_terminal
setup_clean_terminal()
```

**Beneficios:**
- ConfiguraciÃ³n temprana antes de imports
- Respeta flag `--debug` del usuario
- Centralizado y mantenible

### 3. IntegraciÃ³n en `model_orchestrator.py`

```python
from src.utils.log_suppressor import model_loading_context

def _load_inner():
    debug_mode = os.environ.get('JARVIS_DEBUG') == '1'
    with model_loading_context(debug_mode=debug_mode):
        llm = LLM(model=config.path, ...)
```

**Mejoras:**
- Reemplaza el intento anterior con StringIO (no robusto)
- Context manager adecuado con __enter__/__exit__
- RestauraciÃ³n garantizada de stdout/stderr
- Respeta modo debug

## ğŸ“Š Resultado Esperado

### DespuÃ©s de la Mejora

```
2025-11-09 23:03:06 - root - INFO - âœ… Async logging initialized (QueueHandler)

=== Starting Jarvis AI Assistant (Multi-GPU + RAG) ===

âœ“ System monitor initialized
[STATUS] TTS disabled (ENABLE_TTS=false)
âœ“ Storage initialized
[STATUS] Audio effects disabled (ENABLE_AUDIO_EFFECTS=false)
âœ“ Metrics tracker initialized
âœ“ Embedding system (RAG) initialized
âœ“ SmartPromptBuilder initialized
âœ“ LearningManager initialized
âœ“ QualityEvaluator initialized
âœ“ ModelOrchestrator initialized (Multi-GPU)
âœ“ LLM system initialized
[STATUS] âŒ¨ï¸ Text mode - ENABLE_WHISPER=false
âœ“ Voice system initialized
âœ“ Actions initialized
âœ“ Text handler initialized

=== Initializing Jarvis ===

âœ“ GPUs: 1 | Models loaded: 0
[STATUS] Jarvis Text Interface - Escribe 'help' para ver los comandos
âœ“ Health API running on port 8080
âœ“ Metrics collector running (interval=15s)
ğŸŸ¢ > 
```

**Sin:**
- âŒ `[Gloo] Rank 0...`
- âŒ `Loading safetensors...`
- âŒ `Capturing CUDA graphs...`
- âŒ Barras de progreso de tqdm

**Con:**
- âœ… Mensajes informativos de Jarvis
- âœ… Prompt limpio `ğŸŸ¢ >`
- âœ… Respuestas del asistente

## ğŸ§ª Testing

### Script de ValidaciÃ³n: `test_clean_logs.sh`

```bash
./test_clean_logs.sh
```

Verifica:
- âœ… Ausencia de logs de safetensors
- âœ… Ausencia de logs de Gloo
- âœ… Ausencia de logs de CUDA graphs
- âœ… Ausencia de barras de progreso tqdm
- âœ… Presencia de logs normales de Jarvis

### Modo Debug

Para desarrolladores que necesitan ver logs tÃ©cnicos:

```bash
python3 main.py --debug
```

Esto:
- Establece `JARVIS_DEBUG=1`
- Deshabilita todas las supresiones
- Muestra logs completos de vLLM, torch, etc.

## ğŸ”§ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           main.py (entrada)                 â”‚
â”‚  1. Parse --debug flag                      â”‚
â”‚  2. setup_clean_terminal() â† TEMPRANO       â”‚
â”‚  3. Import otros mÃ³dulos                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      log_suppressor.py (core)               â”‚
â”‚  â€¢ configure_quiet_mode()                   â”‚
â”‚  â€¢ suppress_tqdm()                          â”‚
â”‚  â€¢ model_loading_context()                  â”‚
â”‚  â€¢ SuppressedOutput                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    model_orchestrator.py (uso)              â”‚
â”‚  with model_loading_context():              â”‚
â”‚      llm = LLM(...)  â† SILENCIOSO           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Variables de Entorno Configuradas

```bash
TF_CPP_MIN_LOG_LEVEL=3              # TensorFlow
TRANSFORMERS_VERBOSITY=error        # Hugging Face Transformers
TOKENIZERS_PARALLELISM=false        # Tokenizers
VLLM_LOGGING_LEVEL=ERROR           # vLLM
VLLM_CONFIGURE_LOGGING=0           # vLLM autoconfiguration
VLLM_LOGGING_CONFIG_PATH=          # vLLM config path
TORCH_DISTRIBUTED_DETAIL=OFF       # PyTorch Distributed
NCCL_DEBUG=                        # NCCL (NVIDIA)
GLOO_LOG_LEVEL=ERROR              # Gloo backend
```

## ğŸ¯ Loggers Suprimidos

```python
verbose_loggers = [
    'vllm',
    'vllm.engine',
    'vllm.worker',
    'vllm.model_executor',
    'torch',
    'torch.distributed',
    'torch.distributed.distributed_c10d',
    'transformers',
    'sentence_transformers',
    'chromadb',
    'httpx',
    'asyncio',
    'tqdm',
    'filelock',
    'huggingface_hub',
]
```

Cada uno configurado a nivel `CRITICAL` con `propagate=False`.

## âœ… Ventajas

1. **Experiencia de Usuario Mejorada**
   - Terminal limpio y profesional
   - Solo informaciÃ³n relevante
   - Interfaz no contaminada

2. **Mantenible**
   - CÃ³digo centralizado en un mÃ³dulo
   - FÃ¡cil agregar nuevas supresiones
   - Respeta modo debug

3. **Robusto**
   - Context managers con cleanup garantizado
   - Manejo de errores (siempre muestra errores)
   - No interfiere con funcionamiento normal

4. **Flexible**
   - Flag `--debug` para desarrolladores
   - Configurable por entorno
   - Puede redirigir a logs si se necesita

## ğŸš€ Uso

### Usuario Final
```bash
python3 main.py
# Terminal limpio, solo interfaz de usuario
```

### Desarrollador/Debug
```bash
python3 main.py --debug
# Todos los logs tÃ©cnicos visibles
```

### Scripts Automatizados
```bash
JARVIS_DEBUG=0 python3 main.py
# Fuerza modo silencioso
```

## ğŸ“Œ Notas Importantes

- La supresiÃ³n ocurre **antes** de importar librerÃ­as pesadas
- Los logs se redirigen a archivos en `logs/` (configuraciÃ³n existente)
- Los errores **siempre** se muestran, incluso en modo silencioso
- No afecta el logging asÃ­ncrono existente (QueueHandler)
- Compatible con sistema de mÃ©tricas y monitoreo

## ğŸ”® Futuras Mejoras

1. **Niveles de verbosidad**
   - `--quiet`: Solo errores
   - `--normal`: Estado actual
   - `--verbose`: Algunos logs tÃ©cnicos
   - `--debug`: Todo

2. **Filtrado selectivo**
   - Permitir ver logs de una librerÃ­a especÃ­fica
   - `--show-logs=vllm` para debug especÃ­fico

3. **Dashboard de logs**
   - Interfaz web para ver logs en tiempo real
   - Separado de la terminal

## ğŸ“š Referencias

- Python logging: https://docs.python.org/3/library/logging.html
- Context managers: https://docs.python.org/3/library/contextlib.html
- vLLM configuration: https://docs.vllm.ai/
- PyTorch distributed: https://pytorch.org/docs/stable/distributed.html
